{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "70c62e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import re\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from editdistance import D_L_Backtrack, D_L_editDistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c701cf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusFile = 'data/corpus.txt'\n",
    "testCorrectFile = 'data/test-words-correct.txt'\n",
    "testMisspelledFile = 'data/test-words-misspelled.txt'\n",
    "spellErrorsFile = 'data/spell-errors.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94572da",
   "metadata": {},
   "source": [
    "### Read Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "401a455c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCorpus(filename):\n",
    "    raw_corpus = open(filename).read().lower()\n",
    "    corpus = \"\".join([char for char in raw_corpus if char not in string.punctuation])\n",
    "    corpus = re.sub('[\\n\\t]', ' ', corpus)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01895193",
   "metadata": {},
   "source": [
    "### Stopwords Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0b24f3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTokens(corpus, stopwords):\n",
    "    tokens = [token for token in word_tokenize(corpus) if token not in stopwordList]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec17b39",
   "metadata": {},
   "source": [
    "### Frequency Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4fa4018c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFrequencyTable(tokens):\n",
    "    counter = Counter(tokens)\n",
    "    frequencyItems = []\n",
    "    for token, count in counter.items():\n",
    "        frequencyItems.append([token, count, count / lenTokens])\n",
    "    wordFreqTable = pd.DataFrame(sorted(frequencyItems, key=lambda tup: tup[2], reverse=True), columns=['word', 'count', 'percentage'])\n",
    "    return wordFreqTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "84803388",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwordList = stopwords.words('english')\n",
    "corpus = readCorpus(corpusFile)\n",
    "tokens = getTokens(corpus, stopwordList)\n",
    "lenTokens = len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "af5e6c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordFreqTable = getFrequencyTable(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0703ae88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>said</td>\n",
       "      <td>3456</td>\n",
       "      <td>0.006163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>one</td>\n",
       "      <td>3215</td>\n",
       "      <td>0.005733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>may</td>\n",
       "      <td>2538</td>\n",
       "      <td>0.004526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>would</td>\n",
       "      <td>1949</td>\n",
       "      <td>0.003476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>prince</td>\n",
       "      <td>1893</td>\n",
       "      <td>0.003376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pierre</td>\n",
       "      <td>1785</td>\n",
       "      <td>0.003183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>could</td>\n",
       "      <td>1695</td>\n",
       "      <td>0.003023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>time</td>\n",
       "      <td>1509</td>\n",
       "      <td>0.002691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>man</td>\n",
       "      <td>1502</td>\n",
       "      <td>0.002678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>new</td>\n",
       "      <td>1199</td>\n",
       "      <td>0.002138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>first</td>\n",
       "      <td>1155</td>\n",
       "      <td>0.002060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>well</td>\n",
       "      <td>1143</td>\n",
       "      <td>0.002038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>old</td>\n",
       "      <td>1138</td>\n",
       "      <td>0.002029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>face</td>\n",
       "      <td>1122</td>\n",
       "      <td>0.002001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>upon</td>\n",
       "      <td>1108</td>\n",
       "      <td>0.001976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>men</td>\n",
       "      <td>1104</td>\n",
       "      <td>0.001969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>see</td>\n",
       "      <td>1094</td>\n",
       "      <td>0.001951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>natasha</td>\n",
       "      <td>1093</td>\n",
       "      <td>0.001949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>two</td>\n",
       "      <td>1070</td>\n",
       "      <td>0.001908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>andrew</td>\n",
       "      <td>1065</td>\n",
       "      <td>0.001899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word  count  percentage\n",
       "0      said   3456    0.006163\n",
       "1       one   3215    0.005733\n",
       "2       may   2538    0.004526\n",
       "3     would   1949    0.003476\n",
       "4    prince   1893    0.003376\n",
       "5    pierre   1785    0.003183\n",
       "6     could   1695    0.003023\n",
       "7      time   1509    0.002691\n",
       "8       man   1502    0.002678\n",
       "9       new   1199    0.002138\n",
       "10    first   1155    0.002060\n",
       "11     well   1143    0.002038\n",
       "12      old   1138    0.002029\n",
       "13     face   1122    0.002001\n",
       "14     upon   1108    0.001976\n",
       "15      men   1104    0.001969\n",
       "16      see   1094    0.001951\n",
       "17  natasha   1093    0.001949\n",
       "18      two   1070    0.001908\n",
       "19   andrew   1065    0.001899"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordFreqTable.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "42ec12f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createConfusionMatricesFromCorrections(spell_error_samples):\n",
    "        letters = 'abcdefghijklmnopqrstuvwxyz@*'\n",
    "        confusion_matrix_substitution = [[0 for i in range(len(letters))] for j in range(len(letters))]\n",
    "        confusion_matrix_transposition = [[0 for i in range(len(letters))] for j in range(len(letters))]\n",
    "        confusion_matrix_insertion = [[0 for i in range(len(letters))] for j in range(len(letters))]\n",
    "        confusion_matrix_deletion = [[0 for i in range(len(letters))] for j in range(len(letters))]\n",
    "        confusion_matrix = {'deletion': confusion_matrix_deletion,\n",
    "                           'insertion': confusion_matrix_insertion,\n",
    "                           'substitution': confusion_matrix_substitution,\n",
    "                           'transposition': confusion_matrix_transposition}\n",
    "        # For each spell error sample\n",
    "        # backtrack is applied to error and its correct version\n",
    "        # and get a correction such as ('deleted', 'c', 'a')\n",
    "        # then for each correction, confusion matrix [ correction_type] is updated\n",
    "        for (key,spellErrors) in spell_error_samples.items():\n",
    "            for spellError in spellErrors:\n",
    "                operations = D_L_Backtrack(spellError[0], key)\n",
    "                for operation in operations:\n",
    "                        x = char_position(operation[1]) if 0<=char_position(operation[1])<=25 else 27  # 0<=pos<=25 is for letters else it is * (wildcard)\n",
    "                        y = char_position(operation[2]) if operation[2] != '@' and 0<=char_position(operation[2])<=25 else 26 if operation[2] == '@' else 27\n",
    "                        confusion_matrix[operation[0]][x][y]+=spellError[1]\n",
    "\n",
    "        return confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "34600b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readSpellErrors(filename):\n",
    "        spell_errors = []\n",
    "        with open(filename) as fp:\n",
    "            line = fp.readline()\n",
    "            while(line):\n",
    "                spell_errors.append(line[:-1])\n",
    "                line = fp.readline()\n",
    "        spell_error_samples = {}\n",
    "        for spl_error in spell_errors:\n",
    "            spl = spl_error.split(':') # first split it into key and possible misspellings\n",
    "            spell_error_samples[spl[0].lower()] = [] # key is lowered and put in\n",
    "            splErrors = spl[1].split(',') # splErrors are [loking, luing*2]\n",
    "            for err in splErrors:\n",
    "                spell_error_samples[spl[0].lower()].append(err.replace(' ', '').lower())\n",
    "        for se in spell_error_samples.items():\n",
    "            spell_error_samples[se[0]] = []\n",
    "            for err in se[1]:\n",
    "                if('*' in err):\n",
    "                    sp = err.split('*') # If it has a * in it, I split it and take the number\n",
    "                    spell_error_samples[se[0]].append((sp[0], int(sp[1])))\n",
    "                else:\n",
    "                    spell_error_samples[se[0]].append((err, 1)) # else 1 is placed in.\n",
    "        return spell_error_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "edaf3866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_position(letter):\n",
    "    return ord(letter) - 97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "25682848",
   "metadata": {},
   "outputs": [],
   "source": [
    "spell_error_samples = readSpellErrors(spellErrorsFile)\n",
    "confusion_matrix = createConfusionMatricesFromCorrections(spell_error_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceba6b43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238c9385",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43597423",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379f9864",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
