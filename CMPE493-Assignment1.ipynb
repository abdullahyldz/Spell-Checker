{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def editDistance(word1, word2):\n",
    "    len1 = len(word1)\n",
    "    len2 = len(word2)\n",
    "    distanceMap = [[0] for i in range(len1+1)]\n",
    "    distanceMap[0] = [i for i in range(len2+1)]\n",
    "    for i in range(len1+1):\n",
    "        distanceMap[i][0] = i\n",
    "    \n",
    "    for i in range(len1):\n",
    "        for j in range(len2):\n",
    "            adder = 0 if(word1[i]==word2[j]) else 1\n",
    "            dist = min(distanceMap[i+1][j]+1,distanceMap[i][j+1]+1,distanceMap[i][j]+adder)\n",
    "            distanceMap[i+1].append(dist)\n",
    "    \n",
    "    return distanceMap[len1][len2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def D_L_editDistance(word1, word2):\n",
    "    len1 = len(word1)\n",
    "    len2 = len(word2)\n",
    "    distanceMap = [[0] for i in range(len1+1)]\n",
    "    distanceMap[0] = [i for i in range(len2+1)]\n",
    "    for i in range(len1+1):\n",
    "        distanceMap[i][0] = i\n",
    "    \n",
    "    for i in range(1,len1+1):\n",
    "        for j in range(1,len2+1):\n",
    "            adder = 0 if(word1[i-1]==word2[j-1]) else 1\n",
    "            #print(i,j,adder)\n",
    "            dist = min(distanceMap[i][j-1]+1,distanceMap[i-1][j]+1,distanceMap[i-1][j-1]+adder)\n",
    "            if(i>1 and j>1 and word1[i-2:i] == word2[j-2:j][::-1]):\n",
    "                dist = min(distanceMap[i-2][j-2]+1, dist)\n",
    "            distanceMap[i].append(dist)\n",
    "    #print(distanceMap)\n",
    "    return distanceMap[len1][len2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def D_L_Backtrack(word1, word2):\n",
    "    len1 = len(word1)\n",
    "    len2 = len(word2)\n",
    "    distanceMap = [[0] for i in range(len1+1)]\n",
    "    distanceMap[0] = [i for i in range(len2+1)]\n",
    "    for i in range(len1+1):\n",
    "        distanceMap[i][0] = i\n",
    "    \n",
    "    for i in range(1,len1+1):\n",
    "        for j in range(1,len2+1):\n",
    "            adder = 0 if(word1[i-1]==word2[j-1]) else 1\n",
    "            #print(i,j,adder)\n",
    "            dist = min(distanceMap[i][j-1]+1,distanceMap[i-1][j]+1,distanceMap[i-1][j-1]+adder)\n",
    "            if(i>1 and j>1 and word1[i-2:i] == word2[j-2:j][::-1]):\n",
    "                dist = min(distanceMap[i-2][j-2]+1, dist)\n",
    "            distanceMap[i].append(dist)\n",
    "            \n",
    "    i = len1\n",
    "    j = len2\n",
    "    operations = []\n",
    "    while(i>=1 and j>=1):\n",
    "        if(distanceMap[i][j] == distanceMap[i][j-1]+1):\n",
    "            #print('insertion of %s after %s' % (word2[j-1], word1[i-1]))\n",
    "            operations.append(('insertion', word2[j-1], word1[i-1]))\n",
    "            j=j-1\n",
    "        elif(distanceMap[i][j] == distanceMap[i-1][j]+1):\n",
    "            #print('deletion of %s after %s' % (word1[i-1], word1[i-2]))\n",
    "            operations.append(('deletion', word1[i-1], word1[i-2]))\n",
    "            i=i-1\n",
    "        elif(distanceMap[i][j] == distanceMap[i-1][j-1] + (0 if word1[i-1] == word2[j-1] else 1)):\n",
    "            if(not word1[i-1] == word2[j-1]):    \n",
    "                #print('substitution of %s with %s' % (word2[j-1], word1[i-1]))\n",
    "                operations.append(('substitution', word2[j-1], word1[i-1]))\n",
    "            i=i-1\n",
    "            j=j-1\n",
    "        else:\n",
    "            #print('transposition of %s with %s' % (word2[j-1], word1[i-1]))\n",
    "            operations.append(('transposition', word2[j-1], word1[i-1]))\n",
    "            i=i-2\n",
    "            j=j-2\n",
    "    word1=word1[:-1]+'@'\n",
    "    word2=word2[:-1]+'@'\n",
    "    while(i>0):\n",
    "        #print('deletion of %s after %s' % (word1[i-1], word1[i-2]))\n",
    "        operations.append(('deletion', word1[i-1], word1[i-2]))\n",
    "        i=i-1\n",
    "    while(j>0):\n",
    "        #print('insertion of %s after %s' % (word2[j-1], word1[i-1]))\n",
    "        operations.append(('insertion', word2[j-1], word1[i-1]))\n",
    "        j=j-1\n",
    "    return operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenMe(inputString):\n",
    "    inputString = inputString.lower()\n",
    "    outputString = ''\n",
    "    for ch in inputString.replace('--',' ').replace('\\'', ''):\n",
    "        if(ch.isalpha() or ch == ' ' or ch.isnumeric()):\n",
    "            outputString+=ch\n",
    "        else:\n",
    "            outputString+=' '\n",
    "    return outputString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = open('corpusMini.txt').read().lower()\n",
    "corpus2 = tokenMe(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_words_correct = []\n",
    "with open('test-words-correct.txt') as fp:\n",
    "    line = fp.readline()\n",
    "    while(line):\n",
    "        line = tokenMe(line)\n",
    "        test_words_correct.append(line[:-1])\n",
    "        line = fp.readline()\n",
    "test_words_misspelled = []\n",
    "with open('test-words-misspelled.txt') as fp2:\n",
    "    line = fp2.readline()\n",
    "    while(line):\n",
    "        line = tokenMe(line)\n",
    "        test_words_misspelled.append(line[:-1])\n",
    "        line = fp2.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "spell_errors = []\n",
    "with open('spell-errors.txt') as fp:\n",
    "    line = fp.readline()\n",
    "    while(line):\n",
    "        spell_errors.append(line[:-1])\n",
    "        line = fp.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "spell_error_samples = {}\n",
    "for spl_error in spell_errors:\n",
    "    spl = spl_error.split(':')\n",
    "    spell_error_samples[spl[0].lower()] = []\n",
    "    splErrors = spl[1].split(',')\n",
    "    for err in splErrors:\n",
    "        spell_error_samples[spl[0].lower()].append(err.replace(' ', '').lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "for se in spell_error_samples.items():\n",
    "    spell_error_samples[se[0]] = []\n",
    "    for err in se[1]:\n",
    "        if('*' in err):\n",
    "            sp = err.split('*')\n",
    "            spell_error_samples[se[0]].append((sp[0], int(sp[1])))\n",
    "        else:\n",
    "            spell_error_samples[se[0]].append((err,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list=re.split('\\s+',corpus2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 3383\n"
     ]
    }
   ],
   "source": [
    "numTokens = len(word_list)\n",
    "print(\"Number of tokens: %d\" %numTokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'word':[],'freq':[],'percentage':[]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordFreq = []\n",
    "for word in set(word_list):\n",
    "    count = word_list.count(word)\n",
    "    wordFreq.append([word, count, round(count/numTokens,5)])\n",
    "wordFreq = sorted(wordFreq, key=lambda tup: tup[2], reverse=True)\n",
    "df = pd.DataFrame(wordFreq, columns=['word','count','percentage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>162</td>\n",
       "      <td>0.04789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of</td>\n",
       "      <td>110</td>\n",
       "      <td>0.03252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and</td>\n",
       "      <td>96</td>\n",
       "      <td>0.02838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>91</td>\n",
       "      <td>0.02690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>87</td>\n",
       "      <td>0.02572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  word  count  percentage\n",
       "0  the    162     0.04789\n",
       "1   of    110     0.03252\n",
       "2  and     96     0.02838\n",
       "3    a     91     0.02690\n",
       "4   to     87     0.02572"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.sort_values('percentage', ascending=False)\n",
    "df.head(5)\n",
    "#wordFreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_position(letter):\n",
    "    return ord(letter) - 97\n",
    "letters    = 'abcdefghijklmnopqrstuvwxyz@*'\n",
    "confusion_matrix_substitution = [[0 for i in range(len(letters))] for j in range(len(letters))]\n",
    "confusion_matrix_transposition = [[0 for i in range(len(letters))] for j in range(len(letters))]\n",
    "confusion_matrix_insertion = [[0 for i in range(len(letters))] for j in range(len(letters))]\n",
    "confusion_matrix_deletion = [[0 for i in range(len(letters))] for j in range(len(letters))]\n",
    "confusion_matrix = {'deletion': confusion_matrix_deletion,\n",
    "                   'insertion': confusion_matrix_insertion,\n",
    "                   'substitution': confusion_matrix_substitution,\n",
    "                   'transposition': confusion_matrix_transposition}\n",
    "for (key,spellErrors) in spell_error_samples.items():\n",
    "    for spellError in spellErrors:\n",
    "        corrections = D_L_Backtrack(spellError[0], key)\n",
    "        for correction in corrections:\n",
    "            x = char_position(correction[1]) if 0<=char_position(correction[1])<=25 else 27\n",
    "            y = char_position(correction[2]) if correction[2] != '@' and 0<=char_position(correction[2])<=25 else 26 if correction[2] == '@' else 27\n",
    "            #print(correction[0], x, correction[1], y, correction[2], key, spellError)\n",
    "            confusion_matrix[correction[0]][x][y]+=spellError[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2645bdadc18>,\n",
       " <matplotlib.lines.Line2D at 0x2645bdadd30>,\n",
       " <matplotlib.lines.Line2D at 0x2645bdadf28>,\n",
       " <matplotlib.lines.Line2D at 0x2645bdbb0b8>,\n",
       " <matplotlib.lines.Line2D at 0x2645bdbb208>,\n",
       " <matplotlib.lines.Line2D at 0x2645bdbb358>,\n",
       " <matplotlib.lines.Line2D at 0x2645bdbb4a8>,\n",
       " <matplotlib.lines.Line2D at 0x2645bdbb5f8>,\n",
       " <matplotlib.lines.Line2D at 0x2645bdbb748>,\n",
       " <matplotlib.lines.Line2D at 0x2645bdbb898>,\n",
       " <matplotlib.lines.Line2D at 0x2645bdbb9e8>,\n",
       " <matplotlib.lines.Line2D at 0x2645bdbbb38>,\n",
       " <matplotlib.lines.Line2D at 0x2645bdbbc88>,\n",
       " <matplotlib.lines.Line2D at 0x2645bdbbdd8>,\n",
       " <matplotlib.lines.Line2D at 0x2645bdbbf28>,\n",
       " <matplotlib.lines.Line2D at 0x2645bdc10b8>,\n",
       " <matplotlib.lines.Line2D at 0x2645bdc1278>,\n",
       " <matplotlib.lines.Line2D at 0x2645bdc13c8>,\n",
       " <matplotlib.lines.Line2D at 0x2645bdc1518>,\n",
       " <matplotlib.lines.Line2D at 0x2645bdc1668>,\n",
       " <matplotlib.lines.Line2D at 0x2645bdc17b8>,\n",
       " <matplotlib.lines.Line2D at 0x2645bdc1908>,\n",
       " <matplotlib.lines.Line2D at 0x2645bdc1a58>,\n",
       " <matplotlib.lines.Line2D at 0x2645bdc1ba8>,\n",
       " <matplotlib.lines.Line2D at 0x2645bdc1cf8>,\n",
       " <matplotlib.lines.Line2D at 0x2645bdc1e48>,\n",
       " <matplotlib.lines.Line2D at 0x2645bdc1f98>,\n",
       " <matplotlib.lines.Line2D at 0x2645bdc5128>]"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(confusion_matrix['deletion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1 if 'x'=='y' else 2 if 'x'=='a' else 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.00029]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = [lis[2] for lis in wordFreq if lis[0]=='want']\n",
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "testWord = 'whant'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what', 'want']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates1 = [word for word in set(word_list) if(abs(len(word)-len(testWord))<=1)]\n",
    "#candidates2 = [word for word in set(word_list) if editDistance(word,testWord) == 1 ] \n",
    "candidates2 = [candidate for candidate in candidates1 if(editDistance(candidate, testWord)==1)]\n",
    "candidates2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#candidates2 = sorted(candidates1, key=lambda x: editDistance(testWord, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "editDistance('oslo', 'snow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
