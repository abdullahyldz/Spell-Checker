{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "856701e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import re\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from editdistance import D_L_Backtrack, D_L_editDistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bb5cb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusFile = 'data/corpus.txt'\n",
    "testCorrectFile = 'data/test-words-correct.txt'\n",
    "testMisspelledFile = 'data/test-words-misspelled.txt'\n",
    "spellErrorsFile = 'data/spell-errors.txt' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "425103b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = 'abcdefghijklmnopqrstuvwxyz@*'\n",
    "deletionFrame = pd.DataFrame(confusion_matrix['deletion'], columns = list('abcdefghijklmnopqrstuvwxyz@*'), index = list(letters))\n",
    "insertionFrame= pd.DataFrame(confusion_matrix['insertion'], columns = list('abcdefghijklmnopqrstuvwxyz@*'), index = list(letters))\n",
    "substitutionFrame=pd.DataFrame(confusion_matrix['substitution'], columns = list('abcdefghijklmnopqrstuvwxyz@*'), index = list(letters))\n",
    "transpositionFrame=pd.DataFrame(confusion_matrix['transposition'], columns = list('abcdefghijklmnopqrstuvwxyz@*'), index = list(letters))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ea133d",
   "metadata": {},
   "source": [
    "### Read Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f1ef006",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCorpus(filename):\n",
    "    raw_corpus = open(filename).read().lower()\n",
    "    corpus = \"\".join([char if char not in string.punctuation + '\\n\\t' else ' ' for char in raw_corpus ])\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909cf143",
   "metadata": {},
   "source": [
    "### Stopwords Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a9f777cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTokens(corpus, stopwords):\n",
    "    tokens = [token for token in word_tokenize(corpus) if token not in stopwordList]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dc1b01",
   "metadata": {},
   "source": [
    "### Frequency Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1de4738f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFrequencyTable(tokens):\n",
    "    counter = Counter(tokens)\n",
    "    frequencyItems = []\n",
    "    for token, count in counter.items():\n",
    "        frequencyItems.append([token, count, count / lenTokens])\n",
    "    wordFreqTable = pd.DataFrame(sorted(frequencyItems, key=lambda tup: tup[2], reverse=True), columns=['word', 'count', 'percentage'])\n",
    "    return wordFreqTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fbdcd87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwordList = stopwords.words('english')\n",
    "corpus = readCorpus(corpusFile)\n",
    "tokens = getTokens(corpus, stopwordList)\n",
    "lenTokens = len(tokens)\n",
    "setOfTokens = set(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "187eef62",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordFreqTable = getFrequencyTable(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "80514c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>said</td>\n",
       "      <td>3464</td>\n",
       "      <td>0.006121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>one</td>\n",
       "      <td>3371</td>\n",
       "      <td>0.005957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>may</td>\n",
       "      <td>2551</td>\n",
       "      <td>0.004508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pierre</td>\n",
       "      <td>1964</td>\n",
       "      <td>0.003471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>would</td>\n",
       "      <td>1953</td>\n",
       "      <td>0.003451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>prince</td>\n",
       "      <td>1935</td>\n",
       "      <td>0.003419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>could</td>\n",
       "      <td>1700</td>\n",
       "      <td>0.003004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>man</td>\n",
       "      <td>1652</td>\n",
       "      <td>0.002919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>time</td>\n",
       "      <td>1529</td>\n",
       "      <td>0.002702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>natasha</td>\n",
       "      <td>1212</td>\n",
       "      <td>0.002142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>new</td>\n",
       "      <td>1211</td>\n",
       "      <td>0.002140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>well</td>\n",
       "      <td>1198</td>\n",
       "      <td>0.002117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>old</td>\n",
       "      <td>1180</td>\n",
       "      <td>0.002085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>first</td>\n",
       "      <td>1177</td>\n",
       "      <td>0.002080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>andrew</td>\n",
       "      <td>1169</td>\n",
       "      <td>0.002066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>men</td>\n",
       "      <td>1145</td>\n",
       "      <td>0.002023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>two</td>\n",
       "      <td>1138</td>\n",
       "      <td>0.002011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>face</td>\n",
       "      <td>1125</td>\n",
       "      <td>0.001988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>upon</td>\n",
       "      <td>1111</td>\n",
       "      <td>0.001963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>see</td>\n",
       "      <td>1101</td>\n",
       "      <td>0.001946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word  count  percentage\n",
       "0      said   3464    0.006121\n",
       "1       one   3371    0.005957\n",
       "2       may   2551    0.004508\n",
       "3    pierre   1964    0.003471\n",
       "4     would   1953    0.003451\n",
       "5    prince   1935    0.003419\n",
       "6     could   1700    0.003004\n",
       "7       man   1652    0.002919\n",
       "8      time   1529    0.002702\n",
       "9   natasha   1212    0.002142\n",
       "10      new   1211    0.002140\n",
       "11     well   1198    0.002117\n",
       "12      old   1180    0.002085\n",
       "13    first   1177    0.002080\n",
       "14   andrew   1169    0.002066\n",
       "15      men   1145    0.002023\n",
       "16      two   1138    0.002011\n",
       "17     face   1125    0.001988\n",
       "18     upon   1111    0.001963\n",
       "19      see   1101    0.001946"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordFreqTable.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "80bfab99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createConfusionMatricesFromCorrections(spell_error_samples):\n",
    "        def char_position(letter):\n",
    "            return ord(letter) - 97 \n",
    "        confusion_matrix_substitution = [[0 for i in range(len(letters))] for j in range(len(letters))]\n",
    "        confusion_matrix_transposition = [[0 for i in range(len(letters))] for j in range(len(letters))]\n",
    "        confusion_matrix_insertion = [[0 for i in range(len(letters))] for j in range(len(letters))]\n",
    "        confusion_matrix_deletion = [[0 for i in range(len(letters))] for j in range(len(letters))]\n",
    "        confusion_matrix = {'deletion': confusion_matrix_deletion,\n",
    "                           'insertion': confusion_matrix_insertion,\n",
    "                           'substitution': confusion_matrix_substitution,\n",
    "                           'transposition': confusion_matrix_transposition}\n",
    "        # For each spell error sample\n",
    "        # backtrack is applied to error and its correct version\n",
    "        # and get a correction such as ('deleted', 'c', 'a')\n",
    "        # then for each correction, confusion matrix [ correction_type] is updated\n",
    "        for (key,spellErrors) in spell_error_samples.items():\n",
    "            for spellError in spellErrors:\n",
    "                operations = D_L_Backtrack(spellError[0], key)\n",
    "                for operation in operations:\n",
    "                        x = char_position(operation[1]) if 0<=char_position(operation[1])<=25 else 27  # 0<=pos<=25 is for letters else it is * (wildcard)\n",
    "                        y = char_position(operation[2]) if operation[2] != '@' and 0<=char_position(operation[2])<=25 else 26 if operation[2] == '@' else 27\n",
    "                        confusion_matrix[operation[0]][x][y]+=spellError[1]\n",
    "\n",
    "        return confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ca1837c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readSpellErrors(filename):\n",
    "        spell_errors = []\n",
    "        with open(filename) as fp:\n",
    "            line = fp.readline()\n",
    "            while(line):\n",
    "                spell_errors.append(line[:-1])\n",
    "                line = fp.readline()\n",
    "        spell_error_samples = {}\n",
    "        for spl_error in spell_errors:\n",
    "            spl = spl_error.split(':') # first split it into key and possible misspellings\n",
    "            spell_error_samples[spl[0].lower()] = [] # key is lowered and put in\n",
    "            splErrors = spl[1].split(',') # splErrors are [loking, luing*2]\n",
    "            for err in splErrors:\n",
    "                spell_error_samples[spl[0].lower()].append(err.replace(' ', '').lower())\n",
    "        for se in spell_error_samples.items():\n",
    "            spell_error_samples[se[0]] = []\n",
    "            for err in se[1]:\n",
    "                if('*' in err):\n",
    "                    sp = err.split('*') # If it has a * in it, I split it and take the number\n",
    "                    spell_error_samples[se[0]].append((sp[0], int(sp[1])))\n",
    "                else:\n",
    "                    spell_error_samples[se[0]].append((err, 1)) # else 1 is placed in.\n",
    "        return spell_error_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "087d178b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spellErrorSamples = readSpellErrors(spellErrorsFile)\n",
    "confusion_matrix = createConfusionMatricesFromCorrections(spellErrorSamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6dcad46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCandidates(testWord):\n",
    "    # First filter by length\n",
    "    candidatesWithLengthDifference1 = [word for word in setOfTokens if (abs(len(word) - len(testWord)) <= 1)]\n",
    "    # Secondly, filter by edit distance using D_L_editDistance method\n",
    "    candidatesWithEditDistance1 = [candidate for candidate in candidatesWithLengthDifference1 if (D_L_editDistance(candidate, testWord) <= 1)]\n",
    "    return candidatesWithEditDistance1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "162dcefe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['disfranchisements', 'disfranchisement']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getCandidates(\"disfranchisements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "465838ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWordFreq(word):\n",
    "    if(word not in setOfTokens):\n",
    "        return 0\n",
    "    located = wordFreqTable.loc[wordFreqTable['word'] == word]\n",
    "    return float(located['percentage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "57acb126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getProbabilityFromConfusionMatrix(operation):\n",
    "    if(operation[0] == 'insertion'):\n",
    "        series = insertionFrame.loc[operation[1]]\n",
    "        return round(series[operation[2]]/sum(series), 7)\n",
    "    elif(operation[0] == 'deletion'):\n",
    "        series = deletionFrame.loc[operation[1]]\n",
    "        return round(series[operation[2]]/sum(series), 7)\n",
    "\n",
    "    elif(operation[0] == 'substitution'):\n",
    "        series = substitutionFrame.loc[operation[1]]\n",
    "        return round(series[operation[2]]/sum(series), 7)\n",
    "\n",
    "    elif(operation[0] == 'transposition'):\n",
    "        series = transpositionFrame.loc[operation[1]]\n",
    "        return round(series[operation[2]]/sum(series), 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "33c19b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBestCandidate(misspelledWord):\n",
    "    bestCandidateScore = 0\n",
    "    bestCandidate = misspelledWord\n",
    "    candidates = getCandidates(misspelledWord)\n",
    "    for candidate in candidates:\n",
    "        candidateFrequency = getWordFreq(candidate)\n",
    "        operation = D_L_Backtrack(candidate, misspelledWord) # What is the operation to get to candidate from misspelledWord\n",
    "        # operation[0] is enough for words with edit distance 1\n",
    "        probabilityFromConfusionMatrix = getProbabilityFromConfusionMatrix(operation[0]) # P(x|w)\n",
    "        if(probabilityFromConfusionMatrix * candidateFrequency >= bestCandidateScore):\n",
    "            bestCandidateScore = probabilityFromConfusionMatrix * candidateFrequency # P(x|w) * p(x)\n",
    "            bestCandidate = candidate\n",
    "    return bestCandidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "de91772a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1992636"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getWordFreq('hello')\n",
    "\n",
    "operation = D_L_Backtrack('hello', 'hella')\n",
    "probabilityConfusionMatrix = getProbabilityFromConfusionMatrix(operation[0]) # P(x|w)\n",
    "probabilityConfusionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "830bdc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "del 1.7671216415853201e-06\n",
      "ke 3.5342432831706403e-06\n",
      "key 4.5945162681218324e-05\n",
      "el 1.7671216415853201e-06\n",
      "keg 3.5342432831706403e-06\n",
      "ken 8.835608207926601e-06\n"
     ]
    }
   ],
   "source": [
    "candidates = getCandidates('kel')\n",
    "for candidate in candidates:\n",
    "    candidateFrequency = getWordFreq(candidate)\n",
    "    print(candidate, candidateFrequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "21b40c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'keys'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getBestCandidate('keyt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "05f4bebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "getProbabilityFromConfusionMatrix([('substitution', 'k', 'd')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97bcd78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}